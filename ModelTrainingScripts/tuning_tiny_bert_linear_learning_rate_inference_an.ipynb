{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GUDfCQWHx2b"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "kagglehub.login()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJNI-yKUHx2j"
      },
      "outputs": [],
      "source": [
        "sushantgangurde0907_tuning_tiny_bert_linear_learning_rate_e30_f1_88_pytorch_default_2_path = kagglehub.model_download('sushantgangurde0907/tuning-tiny-bert_linear_learning_rate_e30_f1_88/PyTorch/default/2')\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFbEdp7UHx2m",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lF11H_61Hx2n",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-08-30T06:21:45.837121Z",
          "iopub.status.busy": "2025-08-30T06:21:45.836863Z",
          "iopub.status.idle": "2025-08-30T06:21:54.282796Z",
          "shell.execute_reply": "2025-08-30T06:21:54.281908Z",
          "shell.execute_reply.started": "2025-08-30T06:21:45.837099Z"
        },
        "id": "6Oq8LloIHx2o",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-08-30T06:21:54.284529Z",
          "iopub.status.busy": "2025-08-30T06:21:54.284123Z",
          "iopub.status.idle": "2025-08-30T06:21:54.359981Z",
          "shell.execute_reply": "2025-08-30T06:21:54.359321Z",
          "shell.execute_reply.started": "2025-08-30T06:21:54.284509Z"
        },
        "id": "rwmskiuoHx2q",
        "outputId": "632daae6-9db5-4e38-b33a-a9187e3dd11a",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "\n",
        "MODEL_PATH = \"/kaggle/input/tuning-tiny-bert_linear_learning_rate_e30_f1_88/pytorch/default/1\"\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "LABEL_MAP = {'Positive': 2, 'Neutral': 1, 'Negative': 0}\n",
        "REVERSE_LABEL_MAP = {v: k for k, v in LABEL_MAP.items()}\n",
        "\n",
        "print(f\"Using device: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-08-30T06:21:54.360852Z",
          "iopub.status.busy": "2025-08-30T06:21:54.360577Z",
          "iopub.status.idle": "2025-08-30T06:22:13.176535Z",
          "shell.execute_reply": "2025-08-30T06:22:13.175696Z",
          "shell.execute_reply.started": "2025-08-30T06:21:54.360829Z"
        },
        "id": "MX2t9Dx4Hx2t",
        "outputId": "5c9e635b-d013-4aa9-b258-8c0f776e4087",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model from: /kaggle/input/tuning-tiny-bert_linear_learning_rate_e30_f1_88/pytorch/default/1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-08-30 06:22:00.898735: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756534921.086427      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756534921.147982      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model and tokenizer loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "try:\n",
        "    print(f\"Loading model from: {MODEL_PATH}\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)\n",
        "\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    print(\"Model and tokenizer loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    exit()\n",
        "\n",
        "def predict_sentiment(text: str):\n",
        "    \"\"\"\n",
        "    Takes a string of text and returns the predicted sentiment and confidence score.\n",
        "    \"\"\"\n",
        "    if not text.strip():\n",
        "        return \"Invalid Input\", 0.0\n",
        "\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        text,\n",
        "        add_special_tokens=True,\n",
        "        max_length=128, \n",
        "        return_token_type_ids=False,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt', \n",
        "    )\n",
        "\n",
        "    input_ids = inputs['input_ids'].to(DEVICE)\n",
        "    attention_mask = inputs['attention_mask'].to(DEVICE)\n",
        "\n",
        "    with torch.no_grad(): \n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    logits = outputs.logits\n",
        "\n",
        "    prediction_idx = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
        "    confidence = probabilities.max().item()\n",
        "\n",
        "    predicted_label = REVERSE_LABEL_MAP[prediction_idx]\n",
        "\n",
        "    return predicted_label, confidence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-08-30T06:22:13.178489Z",
          "iopub.status.busy": "2025-08-30T06:22:13.177934Z",
          "iopub.status.idle": "2025-08-30T06:22:13.6492Z",
          "shell.execute_reply": "2025-08-30T06:22:13.648446Z",
          "shell.execute_reply.started": "2025-08-30T06:22:13.178467Z"
        },
        "id": "BUBd1CgjHx2x",
        "outputId": "c913a208-5fb2-40ad-80aa-e1a29411374d",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sentiment Analysis Inference ---\n",
            "\n",
            "Text:       'The new update is fantastic and runs so smoothly!'\n",
            "Sentiment:  Positive (Confidence: 0.9282)\n",
            "\n",
            "Text:       'I am so angry, my package never arrived.'\n",
            "Sentiment:  Negative (Confidence: 0.9639)\n",
            "\n",
            "Text:       'The movie was just okay, nothing special about it.'\n",
            "Sentiment:  Neutral (Confidence: 0.8169)\n",
            "\n",
            "Text:       'This is the worst customer service I have ever experienced.'\n",
            "Sentiment:  Negative (Confidence: 0.9062)\n",
            "\n",
            "Text:       'I'm feeling neither happy nor sad about the news.'\n",
            "Sentiment:  Negative (Confidence: 0.5409)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# --- Main Execution ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n--- Sentiment Analysis Inference ---\")\n",
        "\n",
        "    test_texts = [\n",
        "        \"The new update is fantastic and runs so smoothly!\",\n",
        "        \"I am so angry, my package never arrived.\",\n",
        "        \"The movie was just okay, nothing special about it.\",\n",
        "        \"This is the worst customer service I have ever experienced.\",\n",
        "        \"I'm feeling neither happy nor sad about the news.\",\n",
        "    ]\n",
        "\n",
        "    for text in test_texts:\n",
        "        sentiment, conf = predict_sentiment(text)\n",
        "        print(f\"\\nText:       '{text}'\")\n",
        "        print(f\"Sentiment:  {sentiment} (Confidence: {conf:.4f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hNvxLr3Hx2z",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1I633Q5Hx2z",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJcBByf0Hx20",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmyhpSjiHx21",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Hs-Y1u3Hx21",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-08-30T07:24:24.770184Z",
          "iopub.status.busy": "2025-08-30T07:24:24.769406Z",
          "iopub.status.idle": "2025-08-30T07:24:51.074397Z",
          "shell.execute_reply": "2025-08-30T07:24:51.073574Z",
          "shell.execute_reply.started": "2025-08-30T07:24:24.770145Z"
        },
        "id": "CwUD0pJDHx22",
        "outputId": "40155100-cab9-4daa-e282-d3812cc86f70",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Preparing Model Package from: /kaggle/input/tuning-tiny-bert_linear_learning_rate_e30_f1_88/pytorch/default/2 ---\n",
            "\n",
            "Step 1: Loading PyTorch model and tokenizer...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-08-30 07:24:38.347474: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1756538678.528689      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1756538678.580640      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch model loaded successfully.\n",
            "\n",
            "Step 2: Exporting model to ONNX format at: ./sentiment_model_js_package4/model.onnx\n",
            "ONNX export successful.\n",
            "\n",
            "Step 3: Copying configuration files to './sentiment_model_js_package4'...\n",
            "  - Copying 'config.json'...\n",
            "  - Copying 'tokenizer_config.json'...\n",
            "  - Copying 'vocab.txt'...\n",
            "  - Copying 'special_tokens_map.json'...\n",
            "\n",
            "Step 4: Creating complete zip archive: sentiment_model_js4.zip\n",
            "Packaging the following files:\n",
            "  - Adding 'special_tokens_map.json'...\n",
            "  - Adding 'config.json'...\n",
            "  - Adding 'vocab.txt'...\n",
            "  - Adding 'model.onnx'...\n",
            "  - Adding 'tokenizer_config.json'...\n",
            "\n",
            "Zip file created successfully.\n",
            "\n",
            "--- Conversion Complete ---\n",
            "Your JavaScript-ready model is in 'sentiment_model_js4.zip'.\n",
            "Unzip this file in your web project directory.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "PYTORCH_MODEL_PATH = \"/kaggle/input/tuning-tiny-bert_linear_learning_rate_e30_f1_88/pytorch/default/2\"\n",
        "OUTPUT_PACKAGE_DIR = \"./sentiment_model_js_package4\"\n",
        "\n",
        "\n",
        "\n",
        "ZIP_FILENAME = \"sentiment_model_js4.zip\"\n",
        "\n",
        "print(f\"--- Preparing Model Package from: {PYTORCH_MODEL_PATH} ---\")\n",
        "\n",
        "if not os.path.isdir(PYTORCH_MODEL_PATH):\n",
        "    print(f\"\\n[ERROR] The directory '{PYTORCH_MODEL_PATH}' was not found.\")\n",
        "    print(\"Please make sure this path points to your saved model directory.\")\n",
        "    exit()\n",
        "\n",
        "os.makedirs(OUTPUT_PACKAGE_DIR, exist_ok=True)\n",
        "try:\n",
        "    print(\"\\nStep 1: Loading PyTorch model and tokenizer...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(PYTORCH_MODEL_PATH)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(PYTORCH_MODEL_PATH)\n",
        "    model.eval() # Set to evaluat\n",
        "    print(\"PyTorch model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    exit()\n",
        "\n",
        "onnx_output_path = os.path.join(OUTPUT_PACKAGE_DIR, \"model.onnx\")\n",
        "\n",
        "try:\n",
        "    print(f\"\\nStep 2: Exporting model to ONNX format at: {onnx_output_path}\")\n",
        "    dummy_input_ids = torch.randint(0, tokenizer.vocab_size, (1, 128))\n",
        "    dummy_attention_mask = torch.ones(1, 128, dtype=torch.long)\n",
        "    dummy_input = (dummy_input_ids, dummy_attention_mask)\n",
        "\n",
        "    torch.onnx.export(\n",
        "        model,\n",
        "        dummy_input,\n",
        "        onnx_output_path,\n",
        "        input_names=['input_ids', 'attention_mask'],\n",
        "        output_names=['logits'],\n",
        "        dynamic_axes={\n",
        "            'input_ids': {0: 'batch_size'},\n",
        "            'attention_mask': {0: 'batch_size'},\n",
        "            'logits': {0: 'batch_size'}\n",
        "        },\n",
        "        opset_version=14 \n",
        "    )\n",
        "    print(\"ONNX export successful.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during ONNX export: {e}\")\n",
        "    exit()\n",
        "\n",
        "print(f\"\\nStep 3: Copying configuration files to '{OUTPUT_PACKAGE_DIR}'...\")\n",
        "try:\n",
        "    required_files = [\n",
        "        \"config.json\",\n",
        "        \"tokenizer_config.json\",\n",
        "        \"vocab.txt\",\n",
        "        \"special_tokens_map.json\"\n",
        "    ]\n",
        "    for filename in required_files:\n",
        "        source_path = os.path.join(PYTORCH_MODEL_PATH, filename)\n",
        "        destination_path = os.path.join(OUTPUT_PACKAGE_DIR, filename)\n",
        "        if os.path.exists(source_path):\n",
        "            print(f\"  - Copying '{filename}'...\")\n",
        "            shutil.copy(source_path, destination_path)\n",
        "        else:\n",
        "            print(f\"  - WARNING: Expected file '{filename}' not found in source directory. Skipping.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error copying configuration files: {e}\")\n",
        "    exit()\n",
        "\n",
        "print(f\"\\nStep 4: Creating complete zip archive: {ZIP_FILENAME}\")\n",
        "try:\n",
        "    with zipfile.ZipFile(ZIP_FILENAME, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
        "        print(\"Packaging the following files:\")\n",
        "        for filename in os.listdir(OUTPUT_PACKAGE_DIR):\n",
        "            file_path = os.path.join(OUTPUT_PACKAGE_DIR, filename)\n",
        "            print(f\"  - Adding '{filename}'...\")\n",
        "            zf.write(file_path, arcname=filename)\n",
        "\n",
        "    print(\"\\nZip file created successfully.\")\n",
        "    print(f\"\\n--- Conversion Complete ---\")\n",
        "    print(f\"Your JavaScript-ready model is in '{ZIP_FILENAME}'.\")\n",
        "    print(\"Unzip this file in your web project directory.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error creating zip file: {e}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yd89HjsBHx24",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wjt6LK6jHx24",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hspqUlmHHx25",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcARcvZRHx25",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrBtMY9AHx25",
        "trusted": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "tuning-tiny-bert_linear_learning_rate_inference an",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "isSourceIdPinned": true,
          "modelId": 438717,
          "modelInstanceId": 421099,
          "sourceId": 552007,
          "sourceType": "modelInstanceVersion"
        }
      ],
      "dockerImageVersionId": 31090,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
